{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "\n",
    "# - numpy, pandas, matlib, imageio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we need a environment to interact with TPG agents.\n",
    "\n",
    "\n",
    "#### environment - (sends the pixels to agent) -> agent - (selects an action from action set) -> environment -> ..... ####\n",
    "\n",
    "The environment contains \n",
    "\n",
    " - a set of images that possible contains multiple traffic signs. \n",
    " - a piece of rectangle(window) that cut off from the images\n",
    "     - TPG agents only can index pixels inside the window\n",
    "     - TPG angents are able to move this rectangle\n",
    " - an action set from 1 to 4 that repersent the legal action of agents\n",
    "     - 1 -> move up\n",
    "     - 2 -> move left\n",
    "     - 3 -> move down\n",
    "     - 4 -> move right\n",
    " - support functions that allow env to react the inputs from TPG agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#### the environment should contains following features.\n",
    "\n",
    "# input - actions from TPG agents, TPG agent would select one of action from environment action set.\n",
    "\n",
    "# environment react to input - move the rectangle up,down,left or right.\n",
    "\n",
    "# return the pxiels inside the retangle to agent\n",
    "\n",
    "class TrackingEnv:\n",
    "    def __init__(self,dataset,window_width,window_height,step_move,tolerance):\n",
    "        '''\n",
    "        ! you need to ensure the ground true file is shared same repository with ppm images\n",
    "        \n",
    "        Initial enironment at the first, users need to enter \n",
    "        \n",
    "        1. traffic signs dataset \n",
    "        3. the desirable width and height for the window\n",
    "        4. tolerance of windows toward the ground true\n",
    "        \n",
    "        '''\n",
    "        print(\"Setting tracking environment\")\n",
    "        self.dataset = dataset\n",
    "        self.window_width = window_width\n",
    "        self.window_height = window_height\n",
    "        self.tolerance = tolerance\n",
    "        self.step_move = step_move\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    # show its status\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    def __repr__(self):\n",
    "        return 'curr_window #'+str(self.index)+' :\\n'+str(self.curr_window)\n",
    "    def act(self,action):\n",
    "        if action == 1:\n",
    "            self.curr_window.moveUp()\n",
    "        elif action == 2:\n",
    "            self.curr_window.moveLeft()\n",
    "        elif action == 3:\n",
    "            self.curr_window.moveDown()\n",
    "        elif action == 4:\n",
    "            self.curr_window.moveRight()\n",
    "        \n",
    "        return self.curr_window.returnCurrState()\n",
    "\n",
    "    # rest everything to default\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "        self.curr_window = Window( \n",
    "            self.dataset.loc[self.index],\n",
    "            self.window_width, \n",
    "            self.window_height,  \n",
    "        \n",
    "            self.step_move,\n",
    "            self.tolerance\n",
    "        )\n",
    "        return self.curr_window.returnCurrState()[0]\n",
    "    \n",
    "    # next image\n",
    "    def next_image(self):\n",
    "        self.index += 1\n",
    "        self.curr_window = Window( \n",
    "            self.dataset.loc[self.index],\n",
    "            self.window_width, \n",
    "            self.window_height,  \n",
    "        \n",
    "            self.step_move,\n",
    "            self.tolerance \n",
    "        )\n",
    "        return self.curr_window.returnCurrState()[0]\n",
    "    \n",
    "    #show current image\n",
    "    def show_image(self):\n",
    "        plt.imshow(self.curr_window.image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    '''\n",
    "    window is a rectangle frame inside the image, the agent only allow to index the pixel inside this rectangle frame.\n",
    "    \n",
    "    agent send action to window via TrackEnv. Then, window moves itself according to different action and return the lastest reward, and state to agent.\n",
    "       \n",
    "    '''\n",
    "    def __init__(self,record,width,height,step_move,tolerance):\n",
    "        self.tolerance = tolerance\n",
    "        self.image = imageio.imread(record[0])\n",
    "        self.ground_true = record[1:]\n",
    "        self.step_move = step_move\n",
    "        \n",
    "        self.max_height, self.max_width, _ = self.image.shape\n",
    "        self.x1 = int(self.max_width/2 - width)\n",
    "        self.x2 = int(self.max_width/2 + width)\n",
    "        self.y1 = int(self.max_height/2 - height)\n",
    "        self.y2 = int(self.max_height/2 + height)\n",
    "    \n",
    "    #status\n",
    "    def __str__(self):\n",
    "        return 'groud_true:\\n'+str(self.ground_true)\n",
    "        \n",
    "#         self.window = self.image[self.y1:self.y2,self.x1:self.x2]\n",
    "    # actions\n",
    "    def moveUp(self):\n",
    "        if self.y1 > 0:\n",
    "            self.y1 -= self.step_move\n",
    "            self.y2 -= self.step_move\n",
    "    def moveDown(self):\n",
    "        if self.y2 < self.max_height:\n",
    "            self.y1 += self.step_move\n",
    "            self.y2 += self.step_move\n",
    "    def moveLeft(self):\n",
    "        if self.x1 > 0:\n",
    "            self.x1 -= self.step_move\n",
    "            self.x2 -= self.step_move\n",
    "    def moveRight(self):\n",
    "        if self.x2 < self.max_width:\n",
    "            self.x1 += self.step_move\n",
    "            self.x2 += self.step_move\n",
    "    \n",
    "    # return curr state to agent\n",
    "    def returnCurrState(self):\n",
    "        reward,isDone = self.isTargetInsight()\n",
    "#         state = [self.x1,self.x2,self.y1,self.y2]\n",
    "        state = self.image[self.y1:self.y2,self.x1:self.x2]\n",
    "        return (state,\n",
    "               reward,\n",
    "               isDone)\n",
    "    \n",
    "    # if the window contains group true, reward is set to 1. Otherwise, reawrd is set to 0.\n",
    "    def isTargetInsight(self):\n",
    "        \n",
    "        reward = 1 if self.x1 <= self.ground_true.x1 and self.x2 >= self.ground_true.x2 and self.y1 <= self.ground_true.y1 and self.y2 >= self.ground_true.y2 else 0\n",
    "        isDone = reward\n",
    "        \n",
    "        return (reward,isDone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image from dataet and clean data\n",
    "#### current only for single traffic sign tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_traffic_sign_read(f):\n",
    "        data = []\n",
    "        for line in f:\n",
    "            items = line.strip().split(\";\")\n",
    "            items[0] = export_path + items[0]\n",
    "            for i in range(1,5):\n",
    "                items[i] = int(items[i])\n",
    "            data.append(items)\n",
    "        return data\n",
    "    \n",
    "def single_traffic_sign_read(f):\n",
    "    data = []\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        items = line.strip().split(\";\")\n",
    "        if len(lines) == 0:\n",
    "            lines.append(items)\n",
    "        else:\n",
    "            if lines[0][0] != items[0]:\n",
    "                if len(lines) == 1:\n",
    "                    prev = lines[0]\n",
    "                    prev[0] = export_path + prev[0]\n",
    "                    for i in range(1,5):\n",
    "                        prev[i] = int(prev[i])\n",
    "                    data.append(prev)\n",
    "                lines = [items]\n",
    "            else:\n",
    "                lines.append(items)\n",
    "    if len(lines) == 1:\n",
    "                prev = lines[0]\n",
    "                prev[0] = export_path + prev[0]\n",
    "                for i in range(1,5):\n",
    "                    prev[i] = int(prev[i])\n",
    "                data.append(prev)\n",
    "    return data\n",
    "# read ground true data ! only for single traffic sign tracking\n",
    "def read_gt(fname,export_path):\n",
    "    f = open(export_path+fname)\n",
    "\n",
    "#     data = multiple_traffic_sign_read(f)      choose one of two\n",
    "    data = single_traffic_sign_read(f)\n",
    "\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    df = pd.DataFrame(data,columns=[\"fname\",\"x1\",\"y1\",\"x2\",\"y2\",\"type\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path =  \"../res/TrainIJCNN2013/\"\n",
    "fpath       =  \"gt.txt\"\n",
    "dataset = read_gt(fpath,export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import TPG agent and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent\n",
    "#\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform pixel matrix to a single vector.\n",
    "def getState(inState):\n",
    "    # each row is all 1 color\n",
    "    rgbRows = np.reshape(inState,(len(inState[0])*len(inState), 3)).T\n",
    "\n",
    "    # add each with appropriate shifting\n",
    "    # get RRRRRRRR GGGGGGGG BBBBBBBB\n",
    "    return np.add(np.left_shift(rgbRows[0], 16),\n",
    "        np.add(np.left_shift(rgbRows[1], 8), rgbRows[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_state(env):\n",
    "    gt = env.curr_window.ground_true\n",
    "    gx = (gt.x1 + gt.x2)/2\n",
    "    gy = (gt.y1 + gt.y2)/2\n",
    "\n",
    "\n",
    "    x = (env.curr_window.x1 + env.curr_window.x2)/2\n",
    "\n",
    "    y = (env.curr_window.y1 + env.curr_window.y2)/2\n",
    "    \n",
    "    print(\"Distance:\",((gx-x)**2+(gy-y)**2)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting generation #0....\n",
      "min: 0 max: 5 average: 1.05\n",
      "Finish generation #0...in 5.50 sec\n",
      "starting generation #1....\n",
      "min: 0 max: 5 average: 2.4761904761904763\n",
      "Finish generation #1...in 5.28 sec\n",
      "starting generation #2....\n",
      "min: 0 max: 5 average: 4.285714285714286\n",
      "Finish generation #2...in 4.58 sec\n",
      "starting generation #3....\n",
      "min: 0 max: 5 average: 4.285714285714286\n",
      "Finish generation #3...in 4.40 sec\n",
      "starting generation #4....\n",
      "min: 0 max: 5 average: 4.761904761904762\n",
      "Finish generation #4...in 4.66 sec\n",
      "starting generation #5....\n",
      "min: 0 max: 5 average: 4.0476190476190474\n",
      "Finish generation #5...in 4.67 sec\n",
      "starting generation #6....\n",
      "min: 0 max: 5 average: 4.523809523809524\n",
      "Finish generation #6...in 4.83 sec\n",
      "starting generation #7....\n",
      "min: 0 max: 5 average: 4.0\n",
      "Finish generation #7...in 4.79 sec\n",
      "starting generation #8....\n",
      "min: 0 max: 5 average: 4.0476190476190474\n",
      "Finish generation #8...in 4.66 sec\n",
      "starting generation #9....\n",
      "min: 0 max: 5 average: 3.8095238095238093\n",
      "Finish generation #9...in 4.93 sec\n",
      "training complete...in 48.42 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# set the trainer\n",
    "%matplotlib inline\n",
    "ftl = 200 # frame to live\n",
    "level = 10 # how many image used to train\n",
    "generation = 10\n",
    "time_format = '{:.2f}'\n",
    "\n",
    "#setting enironment\n",
    "env = TrackingEnv(\n",
    "                 dataset=        dataset\n",
    "                ,window_width=   50\n",
    "                ,window_height=  50\n",
    "                ,step_move=      5\n",
    "                ,tolerance=      5\n",
    "               )\n",
    "#timer \n",
    "aStart = time.time()\n",
    "\n",
    "#setting trainer\n",
    "trainer = Trainer(actions=range(1,5), teamPopSize=20, rTeamPopSize=20) \n",
    "\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = pd.DataFrame([],columns=['min','max','average']) # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "\n",
    "for gen in range(generation): # generation loop\n",
    "    print('starting generation #'+str(gen)+'....')\n",
    "    \n",
    "    tStart = time.time()\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        \n",
    "        \n",
    "        for l in range(level):\n",
    "            for i in range(ftl): # run episodes \n",
    "                # get action from agent\n",
    "                # must transform to at-least int-32 (for my getState to bitshift correctly)\n",
    "                act = agent.act(getState(np.array(state, dtype=np.int32))) \n",
    "\n",
    "                # feedback from env\n",
    "                state, reward, isDone = env.act(act)\n",
    "                score += reward # accumulate reward in score\n",
    "                if isDone:\n",
    "                    break # end early if losing state\n",
    "            #move to next image\n",
    "            env.next_image()\n",
    "\n",
    "        agent.reward(score) # must reward agent (if didn't already score)\n",
    "        \n",
    "        curScores.append(score) # store score\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "    print('min:',min(curScores),'max:', max(curScores),'average:',sum(curScores)/len(curScores))\n",
    "    print('Finish generation #'+str(gen)+'...in '+time_format.format(time.time()-tStart)+\" sec\")\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.loc['Gen#'+str(gen)] = [min(curScores), max(curScores),sum(curScores)/len(curScores)] # min, max, avg\n",
    "    \n",
    "    trainer.saveToFile('Trainer')\n",
    "    summaryScores.to_csv(path_or_buf='summaryScores.csv')\n",
    "    \n",
    "    trainer.evolve()\n",
    "\n",
    "print(\"training complete...in \"+time_format.format(time.time()-aStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocesses training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAgent(args):\n",
    "    #assign arguments\n",
    "    agent = args[0]\n",
    "    env_name = args[1]\n",
    "    env_queue = args[2]\n",
    "    scoreList = args[3]\n",
    "    level = args[4] \n",
    "    ftl = args[5]\n",
    "\n",
    "    #stats report\n",
    "    tStart = time.time()\n",
    "    \n",
    "    #get env from shared queue\n",
    "    env = env_queue.get()\n",
    "    \n",
    "    # skip if task already done by agent\n",
    "    if agent.taskDone(env_name):\n",
    "#         print('Agent #' + str(agent.agentNum) + ' can skip.')\n",
    "        scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "        env_queue.put(env)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    scoreTotal = 0 # score accumulates over all episodes\n",
    "    for l in range(level): # episode loop\n",
    "        for i in range(ftl): # frame loop\n",
    "            \n",
    "            #agent act\n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32))) \n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone = env.act(act)\n",
    "            scoreTotal += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "        #move to next image\n",
    "        env.next_image()\n",
    "    \n",
    "    agent.reward(scoreTotal,env_name)\n",
    "    scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "    env_queue.put(env)\n",
    "#     print(\"finish prcoess \"+str(mp.Process()._identity[0])+' in '+'{:.2f}'.format(time.time()-tStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "starting generation #0....\n",
      "min: 0 max: 5 average: 1.05\n",
      "Finish generation #0...in 4.81 sec\n",
      "starting generation #1....\n",
      "min: 0 max: 5 average: 2.0\n",
      "Finish generation #1...in 2.99 sec\n",
      "starting generation #2....\n",
      "min: 0 max: 5 average: 3.6\n",
      "Finish generation #2...in 2.38 sec\n",
      "starting generation #3....\n",
      "min: 0 max: 5 average: 3.8\n",
      "Finish generation #3...in 2.18 sec\n",
      "starting generation #4....\n",
      "min: 4 max: 5 average: 4.9523809523809526\n",
      "Finish generation #4...in 1.98 sec\n",
      "starting generation #5....\n",
      "min: 0 max: 5 average: 4.25\n",
      "Finish generation #5...in 2.18 sec\n",
      "starting generation #6....\n",
      "min: 0 max: 5 average: 3.5238095238095237\n",
      "Finish generation #6...in 2.68 sec\n",
      "starting generation #7....\n",
      "min: 0 max: 5 average: 3.8\n",
      "Finish generation #7...in 2.37 sec\n",
      "starting generation #8....\n",
      "min: 0 max: 5 average: 4.5\n",
      "Finish generation #8...in 1.98 sec\n",
      "starting generation #9....\n",
      "min: 0 max: 5 average: 3.85\n",
      "Finish generation #9...in 2.18 sec\n",
      "training complete...in 25.98 sec\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# set the params\n",
    "%matplotlib inline\n",
    "ftl = 200 # frame to live\n",
    "level = 10 # how many image used to train\n",
    "generation = 10\n",
    "num_processes = 4\n",
    "time_format = '{:.2f}'\n",
    "\n",
    "\n",
    "#timer \n",
    "aStart = time.time()\n",
    "\n",
    "#setting process pool\n",
    "man = mp.Manager()\n",
    "#setting enironment\n",
    "env_name = 'Track_Traffic_sign'\n",
    "env_queue = man.Queue()\n",
    "for i in range(num_processes):\n",
    "    env_queue.put(TrackingEnv(\n",
    "                     dataset=        dataset\n",
    "                    ,window_width=   50\n",
    "                    ,window_height=  50\n",
    "                    ,step_move=      5\n",
    "                    ,tolerance=      5))\n",
    "#setting trainer\n",
    "trainer = Trainer(actions=range(1,5), teamPopSize=20, rTeamPopSize=20) \n",
    "\n",
    "\n",
    "\n",
    "summaryScores = pd.DataFrame([],columns=['min','max','average']) # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "\n",
    "for gen in range(generation): # generation loop\n",
    "    print('starting generation #'+str(gen)+'....')\n",
    "    scoreList = man.list()\n",
    "    \n",
    "    tStart = time.time()\n",
    "    \n",
    "    #get agents, noRef to not hold reference to trainer in each one\n",
    "    # don't need reference to trainer in multiprocessing\n",
    "    agents = trainer.getAgents() # swap out agents only at start of generation\n",
    "    \n",
    "    # create pool\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    # run the agents\n",
    "    pool.map(runAgent, \n",
    "        [(agent,env_name, env_queue, scoreList, level, ftl)\n",
    "        for agent in agents])\n",
    "    #wait for pool close\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # apply scores, must do this when multiprocessing\n",
    "    # because agents can't refer to trainer\n",
    "    teams = trainer.applyScores(scoreList)\n",
    "    #generate new population\n",
    "    trainer.evolve(tasks=[env_name])\n",
    "    \n",
    "    curScores = trainer.fitnessStats\n",
    "    print('min:',curScores['min'],'max:', curScores['max'],'average:',curScores['average'])\n",
    "    print('Finish generation #'+str(gen)+'...in '+time_format.format(time.time()-tStart)+\" sec\")\n",
    "    \n",
    "    \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.loc['Gen#'+str(gen)] = [curScores['min'],curScores['max'],curScores['average']] # min, max, avg\n",
    "    \n",
    "    trainer.saveToFile('Trainer')\n",
    "    summaryScores.to_csv(path_or_buf='summaryScores.csv')\n",
    "    \n",
    "print(\"training complete...in \"+time_format.format(time.time()-aStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
