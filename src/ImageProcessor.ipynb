{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "\n",
    "# - numpy, pandas, matlib, imageio\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imageio\n",
    "from tpg.trainer import loadTrainer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we need a environment to interact with TPG agents.\n",
    "\n",
    "\n",
    "#### environment - (sends the pixels to agent) -> agent - (selects an action from action set) -> environment -> ..... ####\n",
    "\n",
    "The environment contains \n",
    "\n",
    " - a set of images that possible contains multiple traffic signs. \n",
    " - a piece of rectangle(window) that cut off from the images\n",
    "     - TPG agents only can index pixels inside the window\n",
    "     - TPG angents are able to move this rectangle\n",
    " - an action set from 1 to 4 that repersent the legal action of agents\n",
    "     - 1 -> move up\n",
    "     - 2 -> move left\n",
    "     - 3 -> move down\n",
    "     - 4 -> move right\n",
    " - support functions that allow env to react the inputs from TPG agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#### the environment should contains following features.\n",
    "\n",
    "# input - actions from TPG agents, TPG agent would select one of action from environment action set.\n",
    "\n",
    "# environment react to input - move the rectangle up,down,left or right.\n",
    "\n",
    "# return the pxiels inside the retangle to agent\n",
    "\n",
    "class TrackingEnv:\n",
    "    def __init__(self,dataset,window_width,window_height,step_move,tolerance):\n",
    "        '''\n",
    "        ! you need to ensure the ground true file is shared same repository with ppm images\n",
    "        \n",
    "        Initial enironment at the first, users need to enter \n",
    "        \n",
    "        1. traffic signs dataset \n",
    "        3. the desirable width and height for the window\n",
    "        4. tolerance of windows toward the ground true\n",
    "        \n",
    "        '''\n",
    "        print(\"Setting tracking environment\")\n",
    "        self.dataset = dataset\n",
    "        self.window_width = window_width\n",
    "        self.window_height = window_height\n",
    "        self.tolerance = tolerance\n",
    "        self.step_move = step_move\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    # show its status\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    def __repr__(self):\n",
    "        return 'curr_window #'+str(self.index)+' :\\n'+str(self.curr_window)\n",
    "    def act(self,action):\n",
    "        if action == 1:\n",
    "            self.curr_window.moveUp()\n",
    "        elif action == 2:\n",
    "            self.curr_window.moveLeft()\n",
    "        elif action == 3:\n",
    "            self.curr_window.moveDown()\n",
    "        elif action == 4:\n",
    "            self.curr_window.moveRight()\n",
    "        \n",
    "        return self.curr_window.returnCurrState()\n",
    "\n",
    "    # rest everything to default\n",
    "    def reset(self):\n",
    "        self.index = 0\n",
    "        self.curr_window = Window( \n",
    "            self.dataset.loc[self.index],\n",
    "            self.window_width, \n",
    "            self.window_height,  \n",
    "        \n",
    "            self.step_move,\n",
    "            self.tolerance\n",
    "        )\n",
    "        return self.curr_window.returnCurrState()[0]\n",
    "    \n",
    "    # next image\n",
    "    def next_image(self):\n",
    "        self.index += 1\n",
    "        self.curr_window = Window( \n",
    "            self.dataset.loc[self.index],\n",
    "            self.window_width, \n",
    "            self.window_height,  \n",
    "        \n",
    "            self.step_move,\n",
    "            self.tolerance \n",
    "        )\n",
    "        return self.curr_window.returnCurrState()[0]\n",
    "    \n",
    "    #show current image\n",
    "    def show_image(self):\n",
    "        plt.imshow(self.curr_window.image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    '''\n",
    "    window is a rectangle frame inside the image, the agent only allow to index the pixel inside this rectangle frame.\n",
    "    \n",
    "    agent send action to window via TrackEnv. Then, window moves itself according to different action and return the lastest reward, and state to agent.\n",
    "       \n",
    "    '''\n",
    "    def __init__(self,record,width,height,step_move,tolerance):\n",
    "        self.tolerance = tolerance\n",
    "        self.image = imageio.imread(record[0])\n",
    "        self.ground_true = record[1:]\n",
    "        self.step_move = step_move\n",
    "        \n",
    "        self.max_height, self.max_width, _ = self.image.shape\n",
    "        self.x1 = int(self.max_width/2 - width)\n",
    "        self.x2 = int(self.max_width/2 + width)\n",
    "        self.y1 = int(self.max_height/2 - height)\n",
    "        self.y2 = int(self.max_height/2 + height)\n",
    "    \n",
    "    #status\n",
    "    def __str__(self):\n",
    "        return 'groud_true:\\n'+str(self.ground_true)\n",
    "        \n",
    "#         self.window = self.image[self.y1:self.y2,self.x1:self.x2]\n",
    "    # actions\n",
    "    def moveUp(self):\n",
    "        if self.y1 > 0:\n",
    "            self.y1 -= self.step_move\n",
    "            self.y2 -= self.step_move\n",
    "    def moveDown(self):\n",
    "        if self.y2 < self.max_height:\n",
    "            self.y1 += self.step_move\n",
    "            self.y2 += self.step_move\n",
    "    def moveLeft(self):\n",
    "        if self.x1 > 0:\n",
    "            self.x1 -= self.step_move\n",
    "            self.x2 -= self.step_move\n",
    "    def moveRight(self):\n",
    "        if self.x2 < self.max_width:\n",
    "            self.x1 += self.step_move\n",
    "            self.x2 += self.step_move\n",
    "    \n",
    "    # return curr state to agent\n",
    "    def returnCurrState(self):\n",
    "        reward,isDone = self.isTargetInsight()\n",
    "#         state = [self.x1,self.x2,self.y1,self.y2]\n",
    "        state = self.image[self.y1:self.y2,self.x1:self.x2]\n",
    "        return (state,\n",
    "               reward,\n",
    "               isDone)\n",
    "    \n",
    "    # if the window contains group true, reward is set to 1. Otherwise, reawrd is set to 0.\n",
    "    def isTargetInsight(self):\n",
    "        \n",
    "        reward = 1 if self.x1 <= self.ground_true.x1 and self.x2 >= self.ground_true.x2 and self.y1 <= self.ground_true.y1 and self.y2 >= self.ground_true.y2 else 0\n",
    "        isDone = reward\n",
    "        \n",
    "        return (reward,isDone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image from dataet and clean data\n",
    "#### current only for single traffic sign tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_traffic_sign_read(f):\n",
    "        data = []\n",
    "        for line in f:\n",
    "            items = line.strip().split(\";\")\n",
    "            items[0] = export_path + items[0]\n",
    "            for i in range(1,5):\n",
    "                items[i] = int(items[i])\n",
    "            data.append(items)\n",
    "        return data\n",
    "    \n",
    "def single_traffic_sign_read(f):\n",
    "    data = []\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        items = line.strip().split(\";\")\n",
    "        if len(lines) == 0:\n",
    "            lines.append(items)\n",
    "        else:\n",
    "            if lines[0][0] != items[0]:\n",
    "                if len(lines) == 1:\n",
    "                    prev = lines[0]\n",
    "                    prev[0] = export_path + prev[0]\n",
    "                    for i in range(1,5):\n",
    "                        prev[i] = int(prev[i])\n",
    "                    data.append(prev)\n",
    "                lines = [items]\n",
    "            else:\n",
    "                lines.append(items)\n",
    "    if len(lines) == 1:\n",
    "                prev = lines[0]\n",
    "                prev[0] = export_path + prev[0]\n",
    "                for i in range(1,5):\n",
    "                    prev[i] = int(prev[i])\n",
    "                data.append(prev)\n",
    "    return data\n",
    "# read ground true data ! only for single traffic sign tracking\n",
    "def read_gt(fname,export_path):\n",
    "    f = open(export_path+fname)\n",
    "\n",
    "#     data = multiple_traffic_sign_read(f)      choose one of two\n",
    "    data = single_traffic_sign_read(f)\n",
    "\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    df = pd.DataFrame(data,columns=[\"fname\",\"x1\",\"y1\",\"x2\",\"y2\",\"type\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path =  \"../res/TrainIJCNN2013/\"\n",
    "fpath       =  \"gt.txt\"\n",
    "dataset = read_gt(fpath,export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import TPG agent and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent\n",
    "#\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform pixel matrix to a single vector.\n",
    "def getState(inState):\n",
    "    # each row is all 1 color\n",
    "    rgbRows = np.reshape(inState,(len(inState[0])*len(inState), 3)).T\n",
    "\n",
    "    # add each with appropriate shifting\n",
    "    # get RRRRRRRR GGGGGGGG BBBBBBBB\n",
    "    return np.add(np.left_shift(rgbRows[0], 16),\n",
    "        np.add(np.left_shift(rgbRows[1], 8), rgbRows[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_state(env):\n",
    "    gt = env.curr_window.ground_true\n",
    "    gx = (gt.x1 + gt.x2)/2\n",
    "    gy = (gt.y1 + gt.y2)/2\n",
    "\n",
    "\n",
    "    x = (env.curr_window.x1 + env.curr_window.x2)/2\n",
    "\n",
    "    y = (env.curr_window.y1 + env.curr_window.y2)/2\n",
    "    \n",
    "    print(\"Distance:\",((gx-x)**2+(gy-y)**2)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tracking environment\n",
      "starting generation #0....\n",
      "min: 3 max: 26 average: 8.9\n",
      "Finish generation #0...in 139.32 sec\n",
      "starting generation #1....\n",
      "min: 3 max: 27 average: 11.421052631578947\n",
      "Finish generation #1...in 133.20 sec\n",
      "starting generation #2....\n",
      "min: 3 max: 26 average: 15.13888888888889\n",
      "Finish generation #2...in 121.67 sec\n",
      "starting generation #3....\n",
      "min: 5 max: 26 average: 22.21212121212121\n",
      "Finish generation #3...in 105.66 sec\n",
      "starting generation #4....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a0fe25b12cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0;32mbreak\u001b[0m \u001b[0;31m# end early if losing state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m#move to next image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# must reward agent (if didn't already score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-667e050c03a2>\u001b[0m in \u001b[0;36mnext_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_move\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnCurrState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-81bef9c5e8e0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, record, width, height, step_move, tolerance)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_move\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Return its reader object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;34m\"Format %s cannot read in mode %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             )\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, format, request)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Open the reader/writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, pilmode, as_gray)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawmode_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mpil_try_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Store args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             self._kwargs = dict(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36mpil_try_read\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# this will raise an IOError if the file is not readable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0msite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://pillow.readthedocs.io/en/latest/installation.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mgetdata\u001b[0;34m(self, band)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \"\"\"\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetband\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# set the trainer\n",
    "%matplotlib inline\n",
    "ftl = 300 # frame to live\n",
    "level = 100 # how many image used to train\n",
    "generation = 10\n",
    "time_format = '{:.2f}'\n",
    "\n",
    "#setting enironment\n",
    "env = TrackingEnv(\n",
    "                 dataset=        dataset\n",
    "                ,window_width=   50\n",
    "                ,window_height=  50\n",
    "                ,step_move=      5\n",
    "                ,tolerance=      5\n",
    "               )\n",
    "#timer \n",
    "aStart = time.time()\n",
    "\n",
    "#setting trainer\n",
    "trainer = Trainer(actions=range(1,5), teamPopSize=40, rTeamPopSize=20) \n",
    "\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = pd.DataFrame([],columns=['min','max','average']) # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "\n",
    "for gen in range(generation): # generation loop\n",
    "    print('starting generation #'+str(gen)+'....')\n",
    "    \n",
    "    tStart = time.time()\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        \n",
    "        \n",
    "        for l in range(level):\n",
    "            for i in range(ftl): # run episodes \n",
    "                # get action from agent\n",
    "                # must transform to at-least int-32 (for my getState to bitshift correctly)\n",
    "                act = agent.act(getState(np.array(state, dtype=np.int32))) \n",
    "\n",
    "                # feedback from env\n",
    "                state, reward, isDone = env.act(act)\n",
    "                score += reward # accumulate reward in score\n",
    "                if isDone:\n",
    "                    break # end early if losing state\n",
    "            #move to next image\n",
    "            env.next_image()\n",
    "\n",
    "        agent.reward(score) # must reward agent (if didn't already score)\n",
    "        \n",
    "        curScores.append(score) # store score\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "    print('min:',min(curScores),'max:', max(curScores),'average:',sum(curScores)/len(curScores))\n",
    "    print('Finish generation #'+str(gen)+'...in '+time_format.format(time.time()-tStart)+\" sec\")\n",
    "    \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.loc['Gen#'+str(gen)] = [min(curScores), max(curScores),sum(curScores)/len(curScores)] # min, max, avg\n",
    "    \n",
    "    trainer.saveToFile('Trainer')\n",
    "    summaryScores.to_csv(path_or_buf='summaryScores.csv')\n",
    "    \n",
    "    trainer.evolve()\n",
    "\n",
    "print(\"training complete...in \"+time_format.format(time.time()-aStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocesses training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAgent(args):\n",
    "    #assign arguments\n",
    "    agent = args[0]\n",
    "    env_name = args[1]\n",
    "    env_queue = args[2]\n",
    "    scoreList = args[3]\n",
    "    level = args[4] \n",
    "    ftl = args[5]\n",
    "\n",
    "    #stats report\n",
    "    tStart = time.time()\n",
    "    \n",
    "    #get env from shared queue\n",
    "    env = env_queue.get()\n",
    "    \n",
    "    # skip if task already done by agent\n",
    "    if agent.taskDone(env_name):\n",
    "#         print('Agent #' + str(agent.agentNum) + ' can skip.')\n",
    "        scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "        env_queue.put(env)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    state = env.reset()\n",
    "    \n",
    "    scoreTotal = 0 # score accumulates over all episodes\n",
    "    for l in range(level): # episode loop\n",
    "        for i in range(ftl): # frame loop\n",
    "            \n",
    "            #agent act\n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32))) \n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone = env.act(act)\n",
    "            scoreTotal += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "        #move to next image\n",
    "        env.next_image()\n",
    "    \n",
    "    agent.reward(scoreTotal,env_name)\n",
    "    scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "    env_queue.put(env)\n",
    "#     print(\"finish prcoess \"+str(mp.Process()._identity[0])+' in '+'{:.2f}'.format(time.time()-tStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "Setting tracking environment\n",
      "starting generation #0....\n",
      "min: 3 max: 26 average: 9.95\n",
      "Finish generation #0...in 35.59 sec\n",
      "starting generation #1....\n",
      "min: 3 max: 26 average: 14.45\n",
      "Finish generation #1...in 28.31 sec\n",
      "starting generation #2....\n",
      "min: 6 max: 26 average: 20.4\n",
      "Finish generation #2...in 14.58 sec\n",
      "starting generation #3....\n",
      "min: 3 max: 26 average: 20.904761904761905\n",
      "Finish generation #3...in 24.90 sec\n",
      "starting generation #4....\n",
      "min: 3 max: 26 average: 22.952380952380953\n",
      "Finish generation #4...in 18.66 sec\n",
      "starting generation #5....\n",
      "min: 3 max: 26 average: 22.666666666666668\n",
      "Finish generation #5...in 18.27 sec\n",
      "starting generation #6....\n",
      "min: 3 max: 26 average: 22.571428571428573\n",
      "Finish generation #6...in 14.76 sec\n",
      "starting generation #7....\n",
      "min: 3 max: 26 average: 24.904761904761905\n",
      "Finish generation #7...in 21.15 sec\n",
      "starting generation #8....\n",
      "min: 3 max: 31 average: 22.095238095238095\n",
      "Finish generation #8...in 21.58 sec\n",
      "starting generation #9....\n",
      "min: 7 max: 31 average: 25.25\n",
      "Finish generation #9...in 19.41 sec\n",
      "starting generation #10....\n",
      "min: 4 max: 31 average: 23.15\n",
      "Finish generation #10...in 12.09 sec\n",
      "starting generation #11....\n",
      "min: 3 max: 31 average: 22.25\n",
      "Finish generation #11...in 25.80 sec\n",
      "starting generation #12....\n",
      "min: 6 max: 31 average: 23.55\n",
      "Finish generation #12...in 15.02 sec\n",
      "starting generation #13....\n",
      "min: 3 max: 31 average: 23.35\n",
      "Finish generation #13...in 18.17 sec\n",
      "starting generation #14....\n",
      "min: 3 max: 31 average: 25.35\n",
      "Finish generation #14...in 17.37 sec\n",
      "starting generation #15....\n",
      "min: 3 max: 31 average: 18.25\n",
      "Finish generation #15...in 21.28 sec\n",
      "starting generation #16....\n",
      "min: 3 max: 31 average: 21.35\n",
      "Finish generation #16...in 20.42 sec\n",
      "starting generation #17....\n",
      "min: 5 max: 31 average: 25.0\n",
      "Finish generation #17...in 18.87 sec\n",
      "starting generation #18....\n",
      "min: 4 max: 31 average: 23.75\n",
      "Finish generation #18...in 24.29 sec\n",
      "starting generation #19....\n",
      "min: 4 max: 32 average: 24.5\n",
      "Finish generation #19...in 15.58 sec\n",
      "starting generation #20....\n",
      "min: 3 max: 32 average: 24.15\n",
      "Finish generation #20...in 21.07 sec\n",
      "starting generation #21....\n",
      "min: 6 max: 32 average: 27.571428571428573\n",
      "Finish generation #21...in 20.68 sec\n",
      "starting generation #22....\n",
      "min: 6 max: 32 average: 26.904761904761905\n",
      "Finish generation #22...in 20.38 sec\n",
      "starting generation #23....\n",
      "min: 6 max: 32 average: 26.952380952380953\n",
      "Finish generation #23...in 20.79 sec\n",
      "starting generation #24....\n",
      "min: 6 max: 34 average: 29.333333333333332\n",
      "Finish generation #24...in 17.58 sec\n",
      "starting generation #25....\n",
      "min: 9 max: 34 average: 31.0\n",
      "Finish generation #25...in 16.26 sec\n",
      "starting generation #26....\n",
      "min: 5 max: 34 average: 27.45\n",
      "Finish generation #26...in 18.81 sec\n",
      "starting generation #27....\n",
      "min: 3 max: 36 average: 26.38095238095238\n",
      "Finish generation #27...in 23.79 sec\n",
      "starting generation #28....\n",
      "min: 3 max: 36 average: 29.35\n",
      "Finish generation #28...in 15.16 sec\n",
      "starting generation #29....\n",
      "min: 6 max: 36 average: 25.05\n",
      "Finish generation #29...in 23.58 sec\n",
      "starting generation #30....\n",
      "min: 3 max: 36 average: 26.25\n",
      "Finish generation #30...in 17.69 sec\n",
      "starting generation #31....\n",
      "min: 3 max: 36 average: 26.25\n",
      "Finish generation #31...in 19.78 sec\n",
      "starting generation #32....\n",
      "min: 3 max: 36 average: 28.428571428571427\n",
      "Finish generation #32...in 16.36 sec\n",
      "starting generation #33....\n",
      "min: 7 max: 36 average: 30.142857142857142\n",
      "Finish generation #33...in 18.47 sec\n",
      "starting generation #34....\n",
      "min: 6 max: 36 average: 31.238095238095237\n",
      "Finish generation #34...in 19.88 sec\n",
      "starting generation #35....\n",
      "min: 7 max: 36 average: 30.523809523809526\n",
      "Finish generation #35...in 15.48 sec\n",
      "starting generation #36....\n",
      "min: 3 max: 36 average: 28.19047619047619\n",
      "Finish generation #36...in 18.67 sec\n",
      "starting generation #37....\n",
      "min: 3 max: 37 average: 25.571428571428573\n",
      "Finish generation #37...in 21.58 sec\n",
      "starting generation #38....\n",
      "min: 3 max: 37 average: 29.6\n",
      "Finish generation #38...in 20.38 sec\n",
      "starting generation #39....\n",
      "min: 3 max: 37 average: 28.714285714285715\n",
      "Finish generation #39...in 23.79 sec\n",
      "starting generation #40....\n",
      "min: 3 max: 37 average: 29.25\n",
      "Finish generation #40...in 15.57 sec\n",
      "starting generation #41....\n",
      "min: 3 max: 37 average: 23.6\n",
      "Finish generation #41...in 24.61 sec\n",
      "starting generation #42....\n",
      "min: 3 max: 37 average: 30.45\n",
      "Finish generation #42...in 16.67 sec\n",
      "starting generation #43....\n",
      "min: 3 max: 37 average: 29.15\n",
      "Finish generation #43...in 22.68 sec\n",
      "starting generation #44....\n",
      "min: 4 max: 37 average: 31.3\n",
      "Finish generation #44...in 13.05 sec\n",
      "starting generation #45....\n",
      "min: 3 max: 37 average: 26.9\n",
      "Finish generation #45...in 24.30 sec\n",
      "starting generation #46....\n",
      "min: 3 max: 37 average: 26.4\n",
      "Finish generation #46...in 21.28 sec\n",
      "starting generation #47....\n",
      "min: 3 max: 37 average: 29.05\n",
      "Finish generation #47...in 17.98 sec\n",
      "starting generation #48....\n",
      "min: 6 max: 37 average: 31.65\n",
      "Finish generation #48...in 18.77 sec\n",
      "starting generation #49....\n",
      "min: 6 max: 37 average: 28.45\n",
      "Finish generation #49...in 24.88 sec\n",
      "training complete...in 996.72 sec\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# is reload agent?\n",
    "reload = True\n",
    "# set the params\n",
    "%matplotlib inline\n",
    "ftl = 200 # frame to live\n",
    "level = 100 # how many image used to train\n",
    "generation = 50\n",
    "num_processes = 16\n",
    "time_format = '{:.2f}'\n",
    "\n",
    "\n",
    "#timer \n",
    "aStart = time.time()\n",
    "\n",
    "#setting process pool\n",
    "man = mp.Manager()\n",
    "#setting enironment\n",
    "env_name = 'Track_Traffic_sign'\n",
    "env_queue = man.Queue()\n",
    "for i in range(num_processes):\n",
    "    env_queue.put(TrackingEnv(\n",
    "                     dataset=        dataset\n",
    "                    ,window_width=   50\n",
    "                    ,window_height=  50\n",
    "                    ,step_move=      5\n",
    "                    ,tolerance=      5))\n",
    "#setting trainer\n",
    "if os.path.exists('./Trainer') and not reload:\n",
    "    trainer = loadTrainer('Trainer')\n",
    "else:\n",
    "    trainer = Trainer(actions=range(1,5), teamPopSize=20, rTeamPopSize=20) \n",
    "\n",
    "\n",
    "\n",
    "summaryScores = pd.DataFrame([],columns=['min','max','average']) # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "\n",
    "for gen in range(generation): # generation loop\n",
    "    print('starting generation #'+str(gen)+'....')\n",
    "    scoreList = man.list()\n",
    "    \n",
    "    tStart = time.time()\n",
    "    \n",
    "    #get agents, noRef to not hold reference to trainer in each one\n",
    "    # don't need reference to trainer in multiprocessing\n",
    "    agents = trainer.getAgents() # swap out agents only at start of generation\n",
    "    \n",
    "    # create pool\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    # run the agents\n",
    "    pool.map(runAgent, \n",
    "        [(agent,env_name, env_queue, scoreList, level, ftl)\n",
    "        for agent in agents])\n",
    "    #wait for pool close\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # apply scores, must do this when multiprocessing\n",
    "    # because agents can't refer to trainer\n",
    "    teams = trainer.applyScores(scoreList)\n",
    "    #generate new population\n",
    "    trainer.evolve(tasks=[env_name])\n",
    "    \n",
    "    curScores = trainer.fitnessStats\n",
    "    print('min:',curScores['min'],'max:', curScores['max'],'average:',curScores['average'])\n",
    "    print('Finish generation #'+str(gen)+'...in '+time_format.format(time.time()-tStart)+\" sec\")\n",
    "    \n",
    "    \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.loc['Gen#'+str(gen)] = [curScores['min'],curScores['max'],curScores['average']] # min, max, avg\n",
    "    \n",
    "    trainer.saveToFile('Trainer')\n",
    "    summaryScores.to_csv(path_or_buf='summaryScores.csv')\n",
    "    \n",
    "print(\"training complete...in \"+time_format.format(time.time()-aStart)+\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
